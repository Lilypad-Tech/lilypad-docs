---
description: A Fast Chat LLM Inference Module for Lilypad
---

# LLM Inference

{% hint style="danger" %}
Under Construction&#x20;
{% endhint %}

## Overview

This LLM Inference Module is a community-contributed module developed at AugmentHack.xyz\
\
The repo for this module can be found [here.](https://github.com/bacalhau-project/lilypad-modicum/blob/main/src/python/modules/fastchat.py)

See the original AugmentHack entry below:

{% embed url="https://devpost.com/software/carpai-fmecgh" %}

{% embed url="https://www.youtube.com/watch?v=bqhNbgqF6ks" %}

## \[CLI] Usage

Usage:

```
lilypad run fastchat:v0.0.1 "paramsStr"
```

Output:





Results:

\
\


## LLM Module Code

{% @github-files/github-code-block url="https://github.com/bacalhau-project/lilypad-modicum/blob/main/src/python/modules/fastchat.py" %}
